{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pouyan9675/RAG-Context-Extraction-Attack/blob/main/document_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2023 Google LLC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKwyTRdwB8aW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXInneX6xx7c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q \"google-generativeai>=0.8.2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWIuwKG2_oWE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a77c04c-7e68-42f8-8d1e-8e5e4a312761",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "# import necessary modules.\n",
        "import base64\n",
        "import copy\n",
        "import json\n",
        "import pathlib\n",
        "import requests\n",
        "\n",
        "\n",
        "import PIL.Image\n",
        "import IPython.display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "try:\n",
        "    # The SDK will automatically read it from the GOOGLE_API_KEY environment variable.\n",
        "    # In Colab get the key from Colab-secrets (\"üîë\" in the left panel).\n",
        "    import os\n",
        "    from google.colab import userdata\n",
        "\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Parse the arguments\n",
        "\n",
        "model = 'gemini-1.5-flash-002' # @param {isTemplate: true}\n",
        "contents_b64 = 'W10=' # @param {isTemplate: true}\n",
        "generation_config_b64 = 'eyJ0ZW1wZXJhdHVyZSI6MSwidG9wX3AiOjAuOTUsInRvcF9rIjo0MCwibWF4X291dHB1dF90b2tlbnMiOjgxOTJ9' # @param {isTemplate: true}\n",
        "safety_settings_b64 = \"e30=\"  # @param {isTemplate: true}\n",
        "\n",
        "gais_contents = json.loads(base64.b64decode(contents_b64))\n",
        "\n",
        "generation_config = json.loads(base64.b64decode(generation_config_b64))\n",
        "safety_settings = json.loads(base64.b64decode(safety_settings_b64))\n",
        "\n",
        "stream = False\n",
        "\n",
        "# Convert and upload the files\n",
        "\n",
        "tempfiles = pathlib.Path(f\"tempfiles\")\n",
        "tempfiles.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "drive = None\n",
        "def upload_file_data(file_data, index):\n",
        "    \"\"\"Upload files to the Files API.\n",
        "\n",
        "    For each file, Google AI Studio either sent:\n",
        "    - a Google Drive ID,\n",
        "    - a URL,\n",
        "    - a file path, or\n",
        "    - The raw bytes (`inline_data`).\n",
        "\n",
        "    The API only understands `inline_data` or it's Files API.\n",
        "    This code, uploads files to the files API where the API can access them.\n",
        "    \"\"\"\n",
        "\n",
        "    mime_type = file_data[\"mime_type\"]\n",
        "    if drive_id := file_data.pop(\"drive_id\", None):\n",
        "        if drive is None:\n",
        "          from google.colab import drive\n",
        "          drive.mount(\"/gdrive\")\n",
        "\n",
        "        path = next(\n",
        "            pathlib.Path(f\"/gdrive/.shortcut-targets-by-id/{drive_id}\").glob(\"*\")\n",
        "        )\n",
        "        print(\"Uploading:\", str(path))\n",
        "        file_info = genai.upload_file(path=path, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if url := file_data.pop(\"url\", None):\n",
        "        response = requests.get(url)\n",
        "        data = response.content\n",
        "        name = url.split(\"/\")[-1]\n",
        "        path = tempfiles / str(index)\n",
        "        path.write_bytes(data)\n",
        "        print(\"Uploading:\", url)\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if name := file_data.get(\"filename\", None):\n",
        "        if not pathlib.Path(name).exists():\n",
        "            raise IOError(\n",
        "                f\"local file: `{name}` does not exist. You can upload files \"\n",
        "                'to Colab using the file manager (\"üìÅ Files\" in the left '\n",
        "                \"toolbar)\"\n",
        "            )\n",
        "        file_info = genai.upload_file(path, display_name=name, mime_type=mime_type)\n",
        "        file_data[\"file_uri\"] = file_info.uri\n",
        "        return\n",
        "\n",
        "    if \"inline_data\" in file_data:\n",
        "        return\n",
        "\n",
        "    raise ValueError(\"Either `drive_id`, `url` or `inline_data` must be provided.\")\n",
        "\n",
        "\n",
        "contents = copy.deepcopy(gais_contents)\n",
        "\n",
        "index = 0\n",
        "for content in contents:\n",
        "    for n, part in enumerate(content[\"parts\"]):\n",
        "        if file_data := part.get(\"file_data\", None):\n",
        "            upload_file_data(file_data, index)\n",
        "            index += 1\n",
        "\n",
        "import json\n",
        "print(json.dumps(contents, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7zAD69vE92b"
      },
      "source": [
        "## Call `generate_content`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "  \"temperature\": 1.0,\n",
        "  \"top_p\": 0.95,\n",
        "  \"top_k\": 40,\n",
        "  \"max_output_tokens\": 8192,\n",
        "  \"response_mime_type\": \"text/plain\",\n",
        "}"
      ],
      "metadata": {
        "id": "i5TpeZNTW5RZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "contents = '''I want to generate imaginary documents as data for a RAG system. Please create a random document that includes imaginary sensitive information, along with annotations for sensitive entities.\n",
        "\n",
        "    Each document should be unique, featuring varied content such as different document titles, personnel, dates, financial figures, identifications, locations, and other relevant details. Ensure that the sensitive entities are diverse in type and sensitivity level.\n",
        "\n",
        "    Avoid reusing information from previously generated documents.\n",
        "\n",
        "    Make sure you check the history of the chat to avoid generating similar documents.\n",
        "\n",
        "    Use the following JSON structure as an example, replacing all details with new content each time:\n",
        "\n",
        "    Example:\n",
        "\n",
        "    {{\n",
        "      \"document_id\": \"doc_XXXX\",\n",
        "      \"document_title\": \"Your Document Title Here\",\n",
        "      \"document_content\": \"This is a placeholder for the document content, which should include various sensitive information about projects, budgets, personnel, locations, and more.\",\n",
        "      \"sensitive_entities\": [\n",
        "        {{\n",
        "          \"entity\": \"Entity Name\",\n",
        "          \"type\": \"entity_type\",\n",
        "          \"sensitivity\": \"sensitivity_level\"\n",
        "        }},\n",
        "        {{\n",
        "          \"entity\": \"Another Entity\",\n",
        "          \"type\": \"another_entity_type\",\n",
        "          \"sensitivity\": \"another_sensitivity_level\",\n",
        "          \"associated_person\": \"Associated Person Name\"\n",
        "        }}\n",
        "      ]\n",
        "    }}\n",
        "\n",
        "    P.S. Make sure the text of your response text start with \"```json\". Also, make sure you do not use any characters or symbol (like un-escaped backslash) that leads to en error.\n",
        "    '''"
      ],
      "metadata": {
        "id": "eA8WPOs8Q8xX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = [\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"parts\": contents,\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "gFg1YBTqSZZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "# Call the model and print the response.\n",
        "gemini = genai.GenerativeModel(model_name=model)\n",
        "\n",
        "num_documents = 1000\n",
        "\n",
        "document_titles = []\n",
        "\n",
        "def ordinal(n):\n",
        "    if 10 <= n % 100 <= 13:\n",
        "        suffix = \"th\"\n",
        "    else:\n",
        "        suffix = {1: \"st\", 2: \"nd\", 3: \"rd\"}.get(n % 10, \"th\")\n",
        "\n",
        "    return f\"{n}{suffix}\"\n",
        "\n",
        "for cardinal_num in range(1, num_documents + 1):\n",
        "    # Completely wrong that I start the session each time.\n",
        "    history_temp = history\n",
        "    if document_titles:\n",
        "        tmp = f\"\\n\\nP.S.2 Remember: make sure to avoid generating projects with document titles similar to the documents that already have been generated, which are : {document_titles}.\"\n",
        "        history_temp[0]['parts'] = history[0]['parts'] + tmp\n",
        "\n",
        "    chat_session = gemini.start_chat(history=history_temp)\n",
        "\n",
        "    ordinal_num = ordinal(cardinal_num)\n",
        "\n",
        "    input_prompt = f\"Generate the {ordinal_num} document.\"\n",
        "    print(f\"Generating the {ordinal_num} document...\")\n",
        "\n",
        "    history.append({\"role\": \"user\", \"parts\": input_prompt})\n",
        "\n",
        "    response = chat_session.send_message(input_prompt)\n",
        "\n",
        "    try:\n",
        "        # Attempt to parse the response text as JSON\n",
        "        response_text_json = json.loads(response.text.strip().strip('`').strip('json'))\n",
        "        history.append({\"role\": \"model\", \"parts\": response_text_json})\n",
        "        document_titles.append(response_text_json[\"document_title\"])\n",
        "        # print(response.text[:50])  # Show a snippet of the response text for reference\n",
        "\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error parsing JSON for document {ordinal_num}. Skipping to the next document.\")\n",
        "        # Optionally log or handle the error in other ways if needed\n",
        "        if history and history[-1][\"parts\"] == input_prompt:\n",
        "            history.pop()\n",
        "\n",
        "print(document_titles)\n",
        "\n",
        "print(\"\\nDone.\")"
      ],
      "metadata": {
        "id": "DwBjp-c6SjKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len([item for item in history if item.get('role') == 'model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC0jxY9ZIPdP",
        "outputId": "35e8e4d6-92f3-4b9f-b273-733f05fd5960"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "responses = [item['parts'] for item in history if item.get('role') == 'model']\n",
        "len(responses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGeR5c_DMm0f",
        "outputId": "d7bb8072-f8bb-4c32-fdf2-2d596ceb5149"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srkRZA68QObU",
        "outputId": "b5b15aea-05a0-464c-8c15-728b0b426958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kuZN5yDSpUP",
        "outputId": "a699db94-3008-4dd5-f084-94b22ac2d017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def format_three_digit(number):\n",
        "    return str(number).zfill(3)\n",
        "\n",
        "for i, item in enumerate(responses, start=1):\n",
        "    print(f\"Processing document {format_three_digit(i)}...\")\n",
        "    filename = f\"/content/drive/MyDrive/CS789_project/json_data/doc_{format_three_digit(i)}__{item['document_title']}.json\"  # Create a unique filename for each object\n",
        "    with open(filename, \"w\") as file:\n",
        "        json.dump(item, file, indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrlLohnmQLSg",
        "outputId": "748574b3-8368-4863-9343-eb8a0c50331e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing document 001...\n",
            "Processing document 002...\n",
            "Processing document 003...\n",
            "Processing document 004...\n",
            "Processing document 005...\n",
            "Processing document 006...\n",
            "Processing document 007...\n",
            "Processing document 008...\n",
            "Processing document 009...\n",
            "Processing document 010...\n",
            "Processing document 011...\n",
            "Processing document 012...\n",
            "Processing document 013...\n",
            "Processing document 014...\n",
            "Processing document 015...\n",
            "Processing document 016...\n",
            "Processing document 017...\n",
            "Processing document 018...\n",
            "Processing document 019...\n",
            "Processing document 020...\n",
            "Processing document 021...\n",
            "Processing document 022...\n",
            "Processing document 023...\n",
            "Processing document 024...\n",
            "Processing document 025...\n",
            "Processing document 026...\n",
            "Processing document 027...\n",
            "Processing document 028...\n",
            "Processing document 029...\n",
            "Processing document 030...\n",
            "Processing document 031...\n",
            "Processing document 032...\n",
            "Processing document 033...\n",
            "Processing document 034...\n",
            "Processing document 035...\n",
            "Processing document 036...\n",
            "Processing document 037...\n",
            "Processing document 038...\n",
            "Processing document 039...\n",
            "Processing document 040...\n",
            "Processing document 041...\n",
            "Processing document 042...\n",
            "Processing document 043...\n",
            "Processing document 044...\n",
            "Processing document 045...\n",
            "Processing document 046...\n",
            "Processing document 047...\n",
            "Processing document 048...\n",
            "Processing document 049...\n",
            "Processing document 050...\n",
            "Processing document 051...\n",
            "Processing document 052...\n",
            "Processing document 053...\n",
            "Processing document 054...\n",
            "Processing document 055...\n",
            "Processing document 056...\n",
            "Processing document 057...\n",
            "Processing document 058...\n",
            "Processing document 059...\n",
            "Processing document 060...\n",
            "Processing document 061...\n",
            "Processing document 062...\n",
            "Processing document 063...\n",
            "Processing document 064...\n",
            "Processing document 065...\n",
            "Processing document 066...\n",
            "Processing document 067...\n",
            "Processing document 068...\n",
            "Processing document 069...\n",
            "Processing document 070...\n",
            "Processing document 071...\n",
            "Processing document 072...\n",
            "Processing document 073...\n",
            "Processing document 074...\n",
            "Processing document 075...\n",
            "Processing document 076...\n",
            "Processing document 077...\n",
            "Processing document 078...\n",
            "Processing document 079...\n",
            "Processing document 080...\n",
            "Processing document 081...\n",
            "Processing document 082...\n",
            "Processing document 083...\n",
            "Processing document 084...\n",
            "Processing document 085...\n",
            "Processing document 086...\n",
            "Processing document 087...\n",
            "Processing document 088...\n",
            "Processing document 089...\n",
            "Processing document 090...\n",
            "Processing document 091...\n",
            "Processing document 092...\n",
            "Processing document 093...\n",
            "Processing document 094...\n",
            "Processing document 095...\n",
            "Processing document 096...\n",
            "Processing document 097...\n",
            "Processing document 098...\n",
            "Processing document 099...\n",
            "Processing document 100...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c9d345e9868"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemini-api/docs\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />Docs on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google-gemini/cookbook/blob/main/quickstarts\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />More notebooks in the Cookbook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oWDZadEZdvFL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}